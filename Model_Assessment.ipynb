{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961111111111111\n"
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "wine = load_wine()\n",
    "svc = SVC(kernel='linear')\n",
    "#help(cross_val_score)\n",
    "scores = cross_val_score(svc, wine.data, wine.target, cv=5)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9550561797752809\n"
     ]
    }
   ],
   "source": [
    "# Leave-one-out Cross Validation\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "scores = cross_val_score(svc, wine.data, wine.target, cv=cv)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score is:  0.8533004713012283\n",
      "Parameters:  {'alpha': 0.01, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning, grid searching\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, random_state=38)\n",
    "\n",
    "best_score = 0\n",
    "for alpha in [0.01, 0.1, 1, 10]:\n",
    "    for max_iter in [100, 1000, 5000, 10000]:\n",
    "        lasso = Lasso(alpha=alpha, max_iter=max_iter)\n",
    "        scores = cross_val_score(lasso, X_train, y_train, cv=6)\n",
    "        score = np.mean(scores)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters={'alpha':alpha, 'max_iter':max_iter}\n",
    "print('Highest score is: ', best_score)\n",
    "print('Parameters: ', best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score is:  0.8885499702025688\n",
      "Parameters:  {'alpha': 0.01, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "# Built-in GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha':[0.01, 0.1, 1.0, 10.0], 'max_iter': [100, 1000, 5000, 10000]}\n",
    "grid_search = GridSearchCV(lasso, params, cv=6)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Highest score is: ', grid_search.score(X_test, y_test))\n",
    "print('Parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(GridSearchCV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
